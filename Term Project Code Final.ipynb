{"cells":[{"cell_type":"markdown","metadata":{"id":"v52S4rZMHsK3"},"source":["# Term Project Group 1\n"]},{"cell_type":"markdown","metadata":{"id":"ceU4aZcRIdh8"},"source":["The Dataset: https://www.kaggle.com/datasets/waqi786/global-black-money-transactions-dataset"]},{"cell_type":"markdown","metadata":{"id":"ZyyUVrF_IioY"},"source":["### Explanation:\n","\n","This dataset gives a solid overview of black money transactions in different countries, focusing on financial activities tied to illegal dealings. It includes details like transaction amounts and risk scores, making it super useful for anyone looking to study financial crime trends or work on anti-money laundering tools.\n","\n","\n","### Dataset:\n","\n","Transaction ID: Unique identifier for each transaction. (e.g., TX0000001)\n","\n","Country: Country where the transaction occurred. (e.g., USA, China)\n","\n","Amount (USD): Transaction amount in US Dollars. (e.g., 150000.00)\n","\n","Transaction Type: Type of transaction. (e.g., Offshore Transfer, Property Purchase)\n","\n","Date of Transaction: The date and time of the transaction. (e.g., 2022-03-15 14:32:00)\n","\n","Person Involved: Name or identifier of the person/entity involved. (e.g., Person_1234)\n","\n","Industry: Industry associated with the transaction. (e.g., Real Estate, Finance)\n","\n","Destination Country: Country where the money was sent. (e.g., Switzerland)\n","\n","Reported by Authority: Whether the transaction was reported to authorities. (e.g., True/False)\n","\n","Source of Money: Origin of the money. (e.g., Legal, Illegal)\n","\n","Money Laundering Risk Score: Risk score indicating the likelihood of money\n","laundering (1-10). (e.g., 8)\n","\n","Shell Companies Involved: Number of shell companies used in the transaction. (e.g., 3)\n","\n","Financial Institution: Bank or financial institution involved in the transaction. (e.g., Bank_567)\n","\n","Tax Haven Country: Country where the money was transferred to a tax haven. (e.g., Cayman Islands)"]},{"cell_type":"markdown","metadata":{"id":"dFAjkKdlH4LW"},"source":["# Pre-process and clean the dataset as appropriate."]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.svm import SVC\n","# from lightgbm import LGBMClassifier\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from imblearn.over_sampling import SMOTE\n","from imblearn.under_sampling import RandomUnderSampler\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n","from sklearn.tree import DecisionTreeClassifier, plot_tree\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.feature_selection import RFE, SelectFromModel, chi2, SelectKBest\n","from sklearn.linear_model import LogisticRegression\n"]},{"cell_type":"markdown","metadata":{"id":"-bNKeluqIu7D"},"source":["## Exploring the data"]},{"cell_type":"markdown","metadata":{},"source":["### Load Data"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Load data\n","df = pd.read_csv('Big_Black_Money_Dataset.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# View the first few rows\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check for missing values\n","df.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get data types\n","df.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.describe()"]},{"cell_type":"markdown","metadata":{},"source":["## Processing the data"]},{"cell_type":"markdown","metadata":{},"source":["### Handle missing values if applicable"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# For numerical features\n","numerical_features = ['Amount (USD)', 'Money Laundering Risk Score', 'Shell Companies Involved']\n","imputer = SimpleImputer(strategy='median')\n","df[numerical_features] = imputer.fit_transform(df[numerical_features])\n","\n","# For categorical features\n","categorical_features = ['Country', 'Transaction Type', 'Person Involved', 'Industry',\n","                        'Destination Country', 'Financial Institution', 'Tax Haven Country']\n","imputer_cat = SimpleImputer(strategy='most_frequent')\n","df[categorical_features] = imputer_cat.fit_transform(df[categorical_features])"]},{"cell_type":"markdown","metadata":{},"source":["### Dropping Features and OHE"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Drop Irrelevant Features\n","df.drop('Transaction ID', axis=1, inplace=True) # Dropped because it is unique for each transaction\n","# df.drop('Person Involved', axis=1, inplace=True) # Frequency Encoding will be implemented\n","# df.drop('Financial Institution', axis=1, inplace=True) # Implement Frequency Encoding\n","df.drop('Date of Transaction', axis=1, inplace=True) # Date of transaction is not relevant\n","\n","# Convert 'Reported by Authority' to integer\n","df['Reported by Authority'] = df['Reported by Authority'].astype(int)\n","\n","# Frequency encoding for 'Financial Institution'\n","df['Financial Institution'] = df.groupby('Financial Institution')['Financial Institution'].transform('count')\n","\n","# Frequency encoding for 'Person Involved'\n","df['Person Involved'] = df.groupby('Person Involved')['Person Involved'].transform('count')\n","\n","# Encode target variable\n","le = LabelEncoder()\n","df['Source of Money'] = le.fit_transform(df['Source of Money'])\n","\n","# One-Hot Encode nominal categorical features\n","nominal_features = ['Country', 'Transaction Type', 'Industry',\n","                    'Destination Country', 'Tax Haven Country']\n","df = pd.get_dummies(df, columns=nominal_features, drop_first=True)\n","\n","dummy_columns = df.filter(like='_').columns\n","df[dummy_columns] = df[dummy_columns].astype(int)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.columns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df['Source of Money'].value_counts()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["features_to_modify = ['Amount (USD)', 'Money Laundering Risk Score', 'Shell Companies Involved']\n","\n","def scale_features(df, features):\n","    df_S = df.copy()\n","    scaler = StandardScaler()\n","    df_S[features] = scaler.fit_transform(df[features])\n","    return df_S\n","\n","def normalize_features(df, features):\n","    df_N = df.copy()\n","    scaler = MinMaxScaler()\n","    df_N[features] = scaler.fit_transform(df[features])\n","    return df_N\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### Biased data correction"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def Undersampling(X,Y, test_size):\n","    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size, random_state=0)\n","    rus = RandomUnderSampler(random_state=0)\n","    X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n","    return X_resampled, y_resampled, X_test, y_test"]},{"cell_type":"markdown","metadata":{},"source":["## Feature Selectors (Optional):"]},{"cell_type":"markdown","metadata":{},"source":["### Feature selector functions"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def cor_selector(X, y,num_feats):\n","    # Your code goes here (Multiple lines)\n","    cor_list = []\n","    feature_name = X.columns.tolist()\n","    for i in feature_name:\n","        cor = np.corrcoef(X[i], y)[0, 1]\n","        cor_list.append(cor)\n","    #print(np.argsort(np.abs(cor_list)))\n","    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n","    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n","    #print(cor_feature)\n","    cor_support = [True if i in cor_feature else False for i in feature_name]\n","    # Your code ends here\n","    return cor_support, cor_feature\n","\n","def chi_squared_selector(X, y, num_feats):\n","    # Your code goes here (Multiple lines)\n","    X_norm = MinMaxScaler().fit_transform(X)\n","    chi_selector = SelectKBest(chi2, k=num_feats)\n","    chi_selector.fit(X_norm, y)\n","    chi_support = chi_selector.get_support()\n","    #print(chi_support)\n","    chi_feature = X.loc[:,chi_support].columns.tolist()\n","    # Your code ends here\n","    return chi_support, chi_feature\n","\n","def rfe_selector(X, y, num_feats):\n","    # Your code goes here (Multiple lines)\n","    rfe_selector = RFE(estimator=LogisticRegression(random_state=42), n_features_to_select=num_feats, step=10, verbose=5)\n","    rfe_selector.fit(X, y)\n","    rfe_support = rfe_selector.support_\n","    rfe_feature = X.loc[:,rfe_support].columns.tolist()\n","    # Your code ends here\n","    return rfe_support, rfe_feature\n","\n","def embedded_log_reg_selector(X, y, num_feats):\n","    # Your code goes here (Multiple lines)\n","    embedded_lr_selector = SelectFromModel(LogisticRegression(penalty=\"l2\", random_state = 42), max_features=num_feats)\n","    embedded_lr_selector.fit(X, y)\n","    embedded_lr_support = embedded_lr_selector.get_support()\n","    embedded_lr_feature = X.loc[:,embedded_lr_support].columns.tolist()\n","    # Your code ends here\n","    return embedded_lr_support, embedded_lr_feature\n","\n","def embedded_rf_selector(X, y, num_feats):\n","    # Your code goes here (Multiple lines)\n","    embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42), max_features=num_feats)\n","    embeded_rf_selector.fit(X, y)\n","    embedded_rf_support = embeded_rf_selector.get_support()\n","    embedded_rf_feature = X.loc[:,embedded_rf_support].columns.tolist()\n","    # Your code ends here\n","    return embedded_rf_support, embedded_rf_feature\n","\n","def embedded_lgbm_selector(X, y, num_feats):\n","    # Your code goes here (Multiple lines)\n","    lgbc = LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=32, colsample_bytree=0.2, reg_alpha=3, reg_lambda=1, min_split_gain=0.01, min_child_weight=40)\n","    embeded_lgbm_selector = SelectFromModel(lgbc, max_features=num_feats)\n","    embeded_lgbm_selector.fit(X, y)\n","    embedded_lgbm_support = embeded_lgbm_selector.get_support()\n","    embedded_lgbm_feature = X.loc[:,embedded_lgbm_support].columns.tolist()\n","    # Your code ends here\n","    return embedded_lgbm_support, embedded_lgbm_feature"]},{"cell_type":"markdown","metadata":{},"source":["### Feature Selectors Combined:"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def autoFeatureSelector(X, y, num_feats, methods=[]):\n","\n","    support_dict = {}\n","\n","    feature_name = list(X.columns)\n","    support_dict['Feature'] = feature_name\n","    \n","    if 'pearson' in methods:\n","        cor_support, cor_feature = cor_selector(X, y, num_feats)\n","        support_dict['Pearson'] = cor_support\n","    if 'chi-square' in methods:\n","        chi_support, chi_feature = chi_squared_selector(X, y, num_feats)\n","        support_dict['Chi-2'] = chi_support\n","    if 'rfe' in methods:\n","        rfe_support, rfe_feature = rfe_selector(X, y, num_feats)\n","        support_dict['RFE'] = rfe_support\n","    if 'log-reg' in methods:\n","        embedded_lr_support, embedded_lr_feature = embedded_log_reg_selector(X, y, num_feats)\n","        support_dict['Logistics'] = embedded_lr_support\n","    if 'rf' in methods:\n","        embedded_rf_support, embedded_rf_feature = embedded_rf_selector(X, y, num_feats)\n","        support_dict['Random Forest'] = embedded_rf_support\n","    if 'lgbm' in methods:\n","        embedded_lgbm_support, embedded_lgbm_feature = embedded_lgbm_selector(X, y, num_feats)\n","        support_dict['LightGBM'] = embedded_lgbm_support \n","    \n","    # Combine all the above feature list and count the maximum set of features that got selected by all methods\n","    \n","    print(\"Combining all methods\")\n","    feature_selection_df = pd.DataFrame(support_dict)\n","    feature_selection_df['Total'] = feature_selection_df.apply(lambda row: np.sum(row[1:].astype(int)), axis=1)\n","    print(\"Sorting features\")\n","    feature_selection_df = feature_selection_df.sort_values(['Total','Feature'] , ascending=False)\n","    feature_selection_df.index = range(1, len(feature_selection_df)+1)\n","    print(\"Selecting best features\")\n","    best_features = feature_selection_df['Feature'].tolist()[:num_feats]\n","    return best_features, feature_selection_df"]},{"cell_type":"markdown","metadata":{},"source":["# Models:"]},{"cell_type":"markdown","metadata":{},"source":["- Utilize GridSearchCV to tune the parameters of each of the models.\n","- Check if better results can be obtained for any of the models.\n","- Discuss your observations regarding model performance.\n","- Randomly remove some features (or based on a certain hypothesis) and re-evaluate the models.\n","- Document your observations concerning model performances."]},{"cell_type":"markdown","metadata":{"id":"sPCRye0hI5va"},"source":["## Logistic Regression: Saif, Dwip\n"]},{"cell_type":"markdown","metadata":{},"source":["### Data for LR"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"QXrNCYAEuQ1i"},"outputs":[],"source":["# Get the data for Logistic Regression\n","df_LR = normalize_features(df, features_to_modify)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Simple LR Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Implement a logistic regression model\n","X = df_LR.drop('Source of Money', axis=1)\n","y = df_LR['Source of Money']\n","\n","# Train-Test Split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n","\n","# Fit the model\n","log_reg = LogisticRegression()\n","log_reg.fit(X_train, y_train)\n","\n","# Predict\n","y_pred = log_reg.predict(X_test)\n","\n","# Evaluate\n","print(\"Logistic Regression\")\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test, y_pred))\n","print(accuracy_score(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{},"source":["### GridSearchCV LR"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Apply Grid Search CV to find the best parameters\n","from sklearn.model_selection import GridSearchCV\n","\n","# Define the hyperparameters\n","param_grid = {\n","    'penalty': ['l1', 'l2'],\n","    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n","}\n","\n","# Instantiate GridSearchCV\n","grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n","\n","# Fit the model\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best parameters\n","print(grid_search.best_params_)\n","print(grid_search.best_score_)\n","print(grid_search.best_estimator_)\n","# Get the best model\n","best_model = grid_search.best_estimator_\n","\n","# Predict\n","y_pred = best_model.predict(X_test)\n","\n","# Evaluate\n","print(\"Logistic Regression\")\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test, y_pred))\n","print(accuracy_score(y_test, y_pred))\n"]},{"cell_type":"markdown","metadata":{"id":"oWV5cWNBI9xr"},"source":["## Decision Tree: Nitish, Sehaj"]},{"cell_type":"markdown","metadata":{},"source":["### Data for DT Model"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["df_DT = df.copy()\n","# Drop person involved\n","df_DT.drop('Person Involved', axis=1, inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["### DT Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Splitting the data into features (X) and target (y)\n","X = df_DT.drop('Source of Money', axis=1)\n","y = df_DT['Source of Money']\n","\n","# Split data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Model training using RandomForestClassifier\n","clf = DecisionTreeClassifier(random_state=42, max_depth=10) # Changed\n","clf.fit(X_train, y_train)\n","\n","# Predictions and accuracy score\n","y_pred = clf.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","print(f\"Model Accuracy: {accuracy:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["conf_matrix = confusion_matrix(y_test, y_pred)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n","\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["feature_importances = clf.feature_importances_\n","feature_names = X.columns\n","importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importances})\n","\n","# Get top 10 features\n","top_features = importance_df.sort_values(by='importance', ascending=False).head(10)\n","\n","#\n","plt.figure(figsize=(12, 8))\n","sns.barplot(x='importance', y='feature', data=top_features)\n","plt.title('Top 10 Feature Importances - Optimized Decision Tree')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Fit a single decision tree to visualize\n","tree_clf = DecisionTreeClassifier(max_depth=4)  # Limit depth for clarity\n","tree_clf.fit(X_train, y_train)\n","\n","# Plot the decision tree\n","plt.figure(figsize=(20, 10))\n","plot_tree(tree_clf, feature_names=X.columns, class_names=['Illegal', 'Legal'], filled=True)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"XMxwAy9DI-Gj"},"source":["## Random Forest: Egor, Ash"]},{"cell_type":"markdown","metadata":{},"source":["### Data for RF Model"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"CHpdHftWuY9G"},"outputs":[],"source":["# Get the data for RF model\n","df_RF = df.copy()"]},{"cell_type":"markdown","metadata":{},"source":["### This needs to be reviewed RF X and Y???"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define features (X) and target (y) - binary classification on 'Money Laundering Risk Score'\n","X_new = df_RF.drop(columns=['Money Laundering Risk Score'])\n","y_new = (df_RF['Money Laundering Risk Score'] >= 5).astype(int)  # Binary target: 1 if score >= 5, else 0\n","\n","# Split the dataset into training and testing sets\n","X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_new, y_new, test_size=0.3, random_state=42)\n","\n","# Initialize and train the RandomForest classifier\n","rf_clf_new = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf_clf_new.fit(X_train_new, y_train_new)\n","\n","# Make predictions on the test set\n","y_pred_new = rf_clf_new.predict(X_test_new)\n","\n","# Generate the confusion matrix and classification report\n","conf_matrix_new = confusion_matrix(y_test_new, y_pred_new)\n","class_report_new = classification_report(y_test_new, y_pred_new)\n","\n","# Display the results\n","print(\"Confusion Matrix:\")\n","print(conf_matrix_new)\n","print(\"\\nClassification Report:\")\n","print(class_report_new)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Split the dataset into training and testing sets\n","X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_new, y_new, test_size=0.3, random_state=42)\n","\n","# Define a simplified parameter grid for GridSearchCV\n","simple_param_grid = {\n","    'n_estimators': [100, 200],\n","    'max_depth': [10, 20],\n","    'min_samples_split': [2, 5],\n","    'min_samples_leaf': [1, 2],\n","    'bootstrap': [True, False]\n","}\n","\n","# Initialize the RandomForest model\n","rf_clf_simplified = RandomForestClassifier(random_state=42)\n","\n","# Set up the GridSearchCV\n","simple_grid_search = GridSearchCV(estimator=rf_clf_simplified,\n","                                  param_grid=simple_param_grid,\n","                                  cv=3,  # 3-fold cross-validation\n","                                  verbose=1,\n","                                  n_jobs=-1)\n","\n","# Fit the simplified grid search model\n","simple_grid_search.fit(X_train_new, y_train_new)\n","\n","# Best hyperparameters from the grid search\n","best_params_simplified = simple_grid_search.best_params_\n","\n","# Train the best model on the training set\n","best_rf_model_simplified = simple_grid_search.best_estimator_\n","best_rf_model_simplified.fit(X_train_new, y_train_new)\n","\n","# Make predictions with the tuned model\n","y_pred_tuned_simplified = best_rf_model_simplified.predict(X_test_new)\n","\n","# Generate confusion matrix and classification report for the tuned model\n","conf_matrix_tuned_simplified = confusion_matrix(y_test_new, y_pred_tuned_simplified)\n","class_report_tuned_simplified = classification_report(y_test_new, y_pred_tuned_simplified)\n","\n","# Output best parameters, confusion matrix, and classification report\n","print(\"Best Hyperparameters:\", best_params_simplified)\n","print(\"Confusion Matrix:\\n\", conf_matrix_tuned_simplified)\n","print(\"Classification Report:\\n\", class_report_tuned_simplified)"]},{"cell_type":"markdown","metadata":{"id":"hiehsO8sI-ch"},"source":["## SGD: Devanshi, James, Abraham"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"lvQ8IYnXueAV"},"outputs":[],"source":["# Stochastic Gradient Descent"]},{"cell_type":"markdown","metadata":{"id":"nfLZECBwI-xV"},"source":["## SVM: Eric, Moosa"]},{"cell_type":"markdown","metadata":{},"source":["### Data for SVM"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"XowPRU4muiu-"},"outputs":[],"source":["df_svm = df.copy()"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["X = df_svm.drop(columns=['Source of Money'])\n","y = df_svm['Source of Money']"]},{"cell_type":"markdown","metadata":{},"source":["### Splitting the data for training and testing"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["# Split the data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"]},{"cell_type":"markdown","metadata":{},"source":["### SVM Model Training and Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["svc_model = SVC()\n","svc_model.fit(X_train, y_train)\n","y_pred = svc_model.predict(X_test)\n","\n","print(confusion_matrix(y_test, y_pred))\n","print(f\"SVC Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n","print(classification_report(y_test, y_pred,  zero_division=1))"]},{"cell_type":"markdown","metadata":{},"source":["### GridSearchCV (Hyper Parameter tuning)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Hyperparameter Tuning using GridSearchCV\n","# SVM GridSearchCV params\n","param_grid_svm = {\n","    'C': [0.1, 1, 10],\n","    'kernel': ['rbf'],\n","    'gamma': [1,0.1,0.01,0.001,0.0001]\n","}\n","grid_svm = GridSearchCV(SVC(), param_grid_svm, cv=5)\n","grid_svm.fit(X_train, y_train)\n","print(f\"Best SVM Parameters: {grid_svm.best_params_}\")\n","print(f\"Best SVM Accuracy: {grid_svm.best_score_}\")"]},{"cell_type":"markdown","metadata":{"id":"6mTwjwTnqDiD"},"source":["# Conclusion and comparison\n"]},{"cell_type":"markdown","metadata":{"id":"WQg4pZMmIX90"},"source":["Present your work including approach and findings during the class on September 24th or 26th, 2024. Each group will have a maximum of 15 minutes to present their project. It is advised that your PowerPoint files to be no longer than 15 slides.\n","\n","Prepare a written technical report of no longer than 15 pages to discuss the problem statement, various steps conducted, summary of findings and conclusions. Submit the report and the notebook file (with proper headings, explanatory comments and code sections) by the midnight of September 29th, 2024."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}
